{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16358987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TTS.utils.manage.ModelManager object at 0x0000018B2643B160>\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 2.566167116165161\n",
      " > Real-time factor: 0.319380389864094\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 1.1177635192871094\n",
      " > Real-time factor: 0.7637173277231273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User_1\\\\Desktop\\\\tts_coqui_1.wav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available ğŸ¸TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Run TTS\n",
    "# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n",
    "# Text to speech list of amplitude values as output\n",
    "wav = tts.tts(text=\"Hello world!\", speaker_wav= r\"C:\\Users\\User_1\\Desktop\\obama.ogg\", language=\"en\")\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\", speaker_wav= r\"C:\\Users\\User_1\\Desktop\\obama.ogg\", language=\"en\", file_path=r\"C:\\Users\\User_1\\Desktop\\tts_coqui_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c2afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text splitted to sentences.\n",
      "['Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§!', 'Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª.']\n",
      " > Processing time: 2.6761815547943115\n",
      " > Real-time factor: 0.5155315495108905\n",
      "âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: C:\\Users\\User_1\\Desktop\\tts_coqui_farsi.wav\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load model\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Define input\n",
    "text = \"Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§! Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.\"\n",
    "speaker_wav = r\"C:\\Users\\User_1\\Desktop\\obama.ogg\"  # Optional but improves voice consistency\n",
    "output_file = r\"C:\\Users\\User_1\\Desktop\\tts_coqui_farsi.wav\"\n",
    "\n",
    "# Generate speech\n",
    "tts.tts_to_file(\n",
    "    text=\"Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§! Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª.\",\n",
    "    speaker_wav=speaker_wav,\n",
    "    language=\"ar\",  # Use Arabic as workaround\n",
    "    file_path=output_file\n",
    ")\n",
    "\n",
    "print(\"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÙØ§Ø±Ø³ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fda37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text splitted to sentences.\n",
      "['Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§!', 'Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.']\n",
      " > Processing time: 0.24735450744628906\n",
      " > Real-time factor: 0.0283446723582455\n",
      "âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: C:\\Users\\User_1\\Desktop\\tts_fa.wav\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.synthesizer import Synthesizer\n",
    "import unicodedata\n",
    "\n",
    "# Paths to your downloaded model files\n",
    "model_path = r\"D:\\Projects\\Offline_translator-webapp\\tts_models\\checkpoint_88000.pth\"\n",
    "config_path = r\"D:\\Projects\\Offline_translator-webapp\\tts_models\\config.json\"\n",
    "output_path = r\"C:\\Users\\User_1\\Desktop\\tts_fa.wav\"\n",
    "\n",
    "# Persian text (make sure it's normalized)\n",
    "text = \"Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§! Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.\"\n",
    "text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "# Initialize the TTS synthesizer\n",
    "synthesizer = Synthesizer(\n",
    "    tts_checkpoint=model_path,\n",
    "    tts_config_path=config_path,\n",
    "    vocoder_checkpoint=None,           # Optional: if your model has a separate vocoder\n",
    "    vocoder_config=None,\n",
    "    use_cuda=True                     # Set True if you want to use GPU\n",
    ")\n",
    "\n",
    "# Generate waveform\n",
    "wavs = synthesizer.tts(text)\n",
    "\n",
    "# Save the audio\n",
    "synthesizer.save_wav(wavs, output_path)\n",
    "\n",
    "print(\"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf8d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Text splitted to sentences.\n",
      "['Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§!', 'Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.']\n",
      " > Processing time: 1.5430762767791748\n",
      " > Real-time factor: 0.17058815930822238\n",
      "âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯: C:\\Users\\User_1\\Desktop\\kamtera_output.wav\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.synthesizer import Synthesizer\n",
    "import unicodedata\n",
    "\n",
    "# Paths to your model and config\n",
    "model_path = r\"D:\\Projects\\Offline_translator-webapp\\tts_models\\checkpoint_88000.pth\"\n",
    "config_path = r\"D:\\Projects\\Offline_translator-webapp\\tts_models\\config.json\"\n",
    "output_path = r\"C:\\Users\\User_1\\Desktop\\kamtera_output.wav\"\n",
    "\n",
    "# Normalize Persian text (important!)\n",
    "text = \"Ø³Ù„Ø§Ù… Ø¯Ù†ÛŒØ§! Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ú¯ÙØªØ§Ø± ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª.\"\n",
    "text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "# Load the Synthesizer\n",
    "synthesizer = Synthesizer(\n",
    "    tts_checkpoint=model_path,\n",
    "    tts_config_path=config_path,\n",
    "    vocoder_checkpoint=None,\n",
    "    vocoder_config=None,\n",
    "    use_cuda=False  # set to True if you have a GPU\n",
    ")\n",
    "\n",
    "# Generate speech\n",
    "wavs = synthesizer.tts(text)\n",
    "\n",
    "# Save to file\n",
    "synthesizer.save_wav(wavs, output_path)\n",
    "\n",
    "print(\"âœ… ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
